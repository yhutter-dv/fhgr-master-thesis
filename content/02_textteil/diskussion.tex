\chapter{Diskussion}
\label{chap_diskussion}
Dieses Kapitel fasst die wichtigsten Aspekte und Erkenntnisse zusammen und thematisiert diese anhand der in Kapitel \ref{chap_einleitung} definierten Forschungsfragen. Ziel ist es, eine konstruktive Diskussion zu führen, in welcher auch die Entscheidungen des Autors reflektiert werden.

\section{Wahl der Technologie}
Um eine echtzeitfähige 3D Datenvisualisierung zu erstellen, ist die Wahl der Technologie massgebend. Um die Frage \textbf{``Welche Technologie ist für eine echtzeitfähige 3D Datenvisualisierung geeignet?''}, zu beantworten, wurde der Fokus bei dieser Arbeit primär auf Spiele Engines sowie Frameworks gelegt. Ein Vorteil von Spiele Engines gegenüber Frameworks ist, dass zur Erstellung von 3D Visualisierungen entsprechende Editoren zur Verfügung stehen. Zudem bieten Engines in der Regel ein breiteres Spektrum von Funktionalitäten und Plattformunterstützung an als Frameworks.

Zudem müssen bei proprietären Engines wie Unity und Unreal entsprechende Lizenzgebühren entrichtet werden. Bei Problemen ist man auf entsprechenden Support seitens des Herstellers angewiesen und hat im Falle von proprietären Engines keine Möglichkeit, diese selbst zu lösen. Je nach Engine ist ausserdem ein nicht zu unterschätzender Lernaufwand sowie entsprechende Hardware notwendig.

Frameworks sind aufgrund des reduzierten Funktionsumfangs platzsparender und ressourcenschonender als Engines. Frameworks bieten Funktionalitäten in Form von wiederverwendbaren Bausteinen (Modulen) an. Es ist die Aufgabe des Programmierers, diese zu einer funktionierenden Gesamtlösung zu vereinen. Je nach Anwendungsfall, Wissensstand und Komplexität sind Frameworks besser geeignet als grosse komplexe Engines. Eine wichtige Voraussetzung hierfür ist jedoch eine gute Dokumentation und entsprechende Anwendungsbeispiele. Im Verlaufe dieser Arbeit hat sich für den Autor gezeigt, dass das Three.js Framework die richtige Wahl für die Umsetzung der Terrainvisualisierung gewesen ist. Zwar mussten viele Aspekte selbst entwickelt werden, jedoch wurde hierdurch auch eine auf die Problemstellung passende Lösung entwickelt. Bei Problemen konnte auf eine grosse Community, gute Dokumentation und viele Anwendungsbeispiele zurückgegriffen werden. 

\section{Datenvorverarbeitung}
Wie bei einem Haus zuerst ein sauberes Fundament errichtet werden muss, ist bei der Datenvisualisierung eine saubere Datenvorverarbeitung von entscheidender Bedeutung. Um die Forschungsfrage \textbf{``Welche Probleme treten bei der Datenvorverarbeitung auf?''} adäquat zu beantworten, werden die wichtigsten Schritte und Erkenntnisse der Datenvorverarbeitung nochmals zusammengefasst und thematisiert.

Als Datengrundlage dienen die beiden swisstopo Datensätze swissALTI3D sowie swissIMAGE. Der swissALTI3D Datensatz beinhaltet das digitale Höhenmodell, wohingegen der swissIMAGE Datensatz die orthografisch korrigierten Luftbilder enthält. Die Kombination dieser beiden Datensätze bildet die Grundlage für die Erstellung der 3D-Modelle und somit die Datenbasis der Terrainvisualisierung. Beide Datensätze stellen jeweils 1km auf 1km grosse Kacheln (Tiles) in unterschiedlicher Auflösung basierend auf dem LV-95 Koordinatensystem zur Verfügung. Um die Komplexität zu reduzieren, hat sich der Autor dazu entschlossen, die gleiche Auflösung (2m pro Pixel) für beide Datensätze zu verwenden. 

Zu Beginn mussten die Daten extrahiert werden. Für den swissALTI3D Datensatz wurden die Höhenwerte hierbei als Graustufenbild gespeichert. Die einzelnen Höhenwerte werden als Pixel abgespeichert, wobei Weiss hohe und Schwarz niedrige Werte repräsentiert. Um ein Gesamtbild zu erhalten, sind anschliessend die einzelnen Tiles anhand des LV-95 Koordinatensystems zu einem Gesamtbild zusammengesetzt worden. Hierbei hat sich gezeigt, dass die Höhenwerte normalisiert werden müssen, da sonst keine fliessenden Übergänge zwischen den einzelnen Tiles existieren.

Grundsätzlich können Daten von verschiedenen Regionen über die swisstopo-Webseite heruntergeladen werden. Die Daten werden hierbei einzeln oder in Form einer CSV-Datei, welche die entsprechenden Download Links enthält, angeboten. Der Autor hat sich hierbei entschlossen, den Downloadvorgang mithilfe eines Python-Skripts auf Basis von CSV-Dateien zu automatisieren. Die einzelnen Tiles werden anschliessend zu einem Gesamtbild zusammengesetzt. Hierbei wurde festgestellt, dass das Gesamtbild schwarze Bereiche, sprich Lücken in den Daten, enthalten kann. Da jedoch die Tiles auf dem LV-95 Koordinatensystem basieren und die einzelnen URLs eine fixe Struktur aufweisen, konnten die fehlenden Daten detektiert und entsprechend mithilfe des Python-Skripts geschlossen werden. Da Grafikkarten Bilder in einer quadratischen Auflösung bevorzugen, wurde das Gesamtbild ebenfalls auf einen quadratischen Ausschnitt eingeschränkt.

Anschliessend wurde das Gesamtbild in mehrere Tiles mit unterschiedlichen Auflösungen (LOD-Level) aufgeteilt. Die einzelnen LOD-Level entsprechen hierbei den einzelnen Nodes der Quadtree Datenstruktur. Beim Erstellen der einzelnen Tiles in unterschiedlichen Auflösungen offenbarte sich jedoch ein neues Problem. Zwischen den einzelnen Tiles besteht kein Übergangsbereich. Dies führte dazu, dass Risse entstehen. Um dieses Problem zu lösen, mussten jeweils an den Rändern die Höhenwerte der Nachbarn mitkopiert werden.

\section{Umsetzung der Visualisierung}
Die Umsetzung einer echtzeitfähigen Terrainvisualisierung ist mit entsprechenden Hürden verbunden. Um hierbei die Frage \textbf{``Welche Probleme treten bei der 3D Datenvisualisierung von Gebirgen auf?''} entsprechend zu beantworten, müssen verschiedene Aspekte thematisiert werden. Eine grundlegende Voraussetzung sind sowohl eine saubere Datenvorverarbeitung als auch die Wahl des korrekten Algorithmus. Der Autor hat sich für den Quadtree Algorithmus entschieden. Mithilfe des Quadtree war es möglich, grosse geografische Gebiete effizient zu unterteilen. Der Quadtree wird abhängig von der aktuellen Kameraposition sowie dem Abstand zu den einzelnen Nodes laufend aktualisiert.

Anhand dieser Unterteilung und auf Basis der vorverarbeiteten Daten, sind anschliessend die entsprechenden 3D-Modelle erstellt worden. Als geometrische Grundstruktur wurde ein sternförmiges Punktegitter gewählt. Die einzelnen Vertices des Gitters werden anhand der Höhendaten mithilfe eines Vertex Shaders entsprechend verschoben. Die Texturierung der Geometrie erfolgt auf Basis der Luftbilder innerhalb des Fragment Shaders. 

Bei der eigentlichen Darstellung der Modelle zeigte sich das nächste Problem. Treffen zwei Geometrien mit einer unterschiedlichen Baumtiefe aufeinander, so bilden sich ebenfalls Risse. Grund hierfür ist, dass die Punkte an den Kanten der Geometrien nicht aneinander passen und so Risse entstehen. Die Lösung dieses Problems war die Index Stitching Methode. Damit das Index Stitching jedoch funktioniert, musste auch sichergestellt werden, dass sich benachbarte Nodes im Quadtree um maximal eine Baumtiefe unterscheiden. Hierzu musste der Quadtree entsprechend ausbalanciert werden. Um die Korrektheit des Quadtrees sowie der Index-Stitching Methode zu verifizieren, wurden ebenfalls entsprechende Hilfsvisualisierungen erstellt.

\section{Ästhetik}
Nebst der eigentlichen Visualisierung spielt auch die Ästhetik eine wichtige Rolle. Die Frage \textbf{``Wie kann die Ästhethik einer 3D Terrainvisualisierung beeinflusst werden?''} umfasst hierbei mehrere Facetten. Mithilfe von \acrshort{HDR} Texturen wurde das Lichtspektrum der einzelnen Farben verbessert. In Kombination mit unterschiedlichen Tone Mapping Verfahren konnten so verschiedene ästhetische Variationen der Visualisierung erstellt werden.

Während sich der Nutzer mithilfe der implementierten Steuerungselemente durch das Terrain bewegt, können je nach Neigung und Betrachtungswinkel verwaschene Texturen in der Ferne entstehen. Um diese Problematik zu lösen, wurde das Anisotropic Filtering von Three.js verwendet. Um das Gefühl zu vermitteln, dass sich die Visualisierung in einer wirklichen Welt befindet, wurde auch ein entsprechender Himmel mit Sonnenstand sowie Tag- und Nachtzyklus umgesetzt. Hierzu konnte auf das breite Ökosystem von Three.js zurückgegriffen werden.

Damit die Auswirkungen der oben beschriebenen Verfahren in Echtzeit observiert werden können, sind entsprechende UI-Elemente (Tweaks) zur Veränderung der Parameter implementiert worden. 

\section{Optimierungen}
Im Zentrum der Optimierung steht die Forschungsfrage \textbf{``Welche Optimierungen sind notwendig, um die Echtzeitfähigkeit der Visualisierung zu gewährleisten?''}. Um diese Frage zu beantworten, musste in einem ersten Schritt die eigentliche Performanz gemessen werden. Für die Messung wurde die Regionen Chur verwendet. Die Messung erfolgte hierbei auf einem Macbook Pro M3 Max, welches an einen Monitor mit einer Auflösung von 5120 auf 2880 Pixel angeschlossen war. Mithilfe der Bibliothek \textit{stats-gl} konnten wichtige Metriken wie Bildwiederholrate sowie CPU- und GPU-Auslastung in Echtzeit mithilfe von Grafen visualisiert werden. Hierbei hat sich gezeigt, dass die Terrainvisualisierung das vordefinierte Ziel von 60 Bildern in der Sekunde erfüllt. Hierzu wurden verschiedene Optimierungen vorgenommen. Da der Quadtree Algorithmus pro Frame ausgeführt werden muss und hierbei je nach grösse der Region eine gewisse Komplexität entsteht, hat sich der Autor entschlossen, diesen mithilfe eines Webworkers in einen separaten Thread auszulagern. Um zudem keine Verzögerungen beim dynamischen Laden von Bildern zu verursachen, werden die Bilder beim Start der Visualisierung vorgeladen.

Während sich der Nutzer durch das Gebirge bewegte, konnten kleine Unterbrechungen registriert werden. Mithilfe der integrierten Browser Monitoring-Tools wurden zwei Probleme identifiziert. Das erste Problem bestand in der Übersetzung von TSL nach GLSL/WGSL. Die Transpilation lief hierbei auf dem CPU ab und benötigte zu viel Zeit. Die Lösung dieses Problems bestand darin, auf das robustere WebGL Backend von Three.js zu wechseln und die Shader direkt in der nativen Sprache (GLSL) zu schreiben. Somit konnte der Übersetzungsschritt von TSL zu GLSL eliminiert werden. Eine weitere Problematik hat sich beim Dekodieren der Bilddateien gezeigt. Damit die Bilder von der Grafikkarte entsprechend verarbeitet werden können, müssen diese zuerst dekodiert und vom CPU an die GPU gesendet werden. Dieser Dekodierungsschritt hat ebenfalls zu Verzögerungen geführt. Um das Dekodierungsproblem zu lösen, wurden die Bilder in das für Grafikkarten optimierte KTX2-Format umgewandelt. Dieses Format hat den Vorteil, dass die Bilder nicht dekodiert werden müssen und direkt an die Grafikkarte gesendet werden können. Mithilfe dieser Optimierungen konnten die restlos Unterbrechungen beseitigt werden.