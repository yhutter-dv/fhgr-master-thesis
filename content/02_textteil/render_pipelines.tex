\chapter{Render Pipeline}
\label{chap_render_pipelines}
Um eine effiziente und durchdachte 3D-Visualisierung zu gestalten ist ein technisches Grundverständnis für die Art und Weise wie Grafikschnittstellen funktionieren von Nöten. Dieses Kapitel soll einen Überblick über die wichtigsten Terminologien und Konzepte diesbezüglich bieten. Ähnlich wie bei einer Data Visualization Pipeline, welche die Schritte und Prozesse vom Vorverarbeiten der Daten bis hin zur Algorithmik und die Art und Weise, wie die Daten dargestellt werden beschreibt, zeigt eine Render Pipeline welche Schritte und Prozesse innerhalb der Grafikkarte ablaufen, bis ein Bild der 3D-Visualisierung entsteht. Nachfolgend wird auf die wichtigsten Schritte innerhalb einer Render Pipeline eingegangen und die wichtigsten Konzepte zur Grafikprogrammierung wie Shader auf einer hohen Flugebene behandelt.

\section{Aubau einer Render Pipeline}
Grundsätzlich ist der genaue Aufbau einer Render Pipeline von der entsprechenden Grafikschnittstelle (DirectX, OpenGL/Vulkan, Metal), welche je nach Betriebssystem unterschiedlich sein kann, abhängig. Oftmals unterscheiden sich jedoch die Pipelines nur in der Terminologie, die einzelnen Schritte und Konzepte bleiben im Grossen und Ganzen bestehend. Als Vorlage zur Erklärung der einzelnen Schritte dient uns die Render Pipeline in Abbildung \ref{fig_render_pipeline}. 
\begin{figure}[H]
    \caption{Aufbau einer Render Pipeline\parencite{render_pipeline_2023}}
    \includegraphics[width=.5\linewidth]{content/00_assets/render_pipeline.png}
    \label{fig_render_pipeline}
\end{figure}

Um 3D Elemente werden von Grafikkarten mithilfe von vielen verschiedenen Dreiecken dargestellt. Die Dreiecke selbst bestehen wiederum aus einzelnen Punkten, welche als Vertices bezeichnet werden. Als Dateninput benutzen Grafikkarten einzelne Vertices und setzen diese dann zu Dreiecken und schliesslich zu kompletten 3D Visualisierungen zusammen. Bis die eigentlichen 3D-Visualisierungen entstehen, werden mehrere Prozessschritte durchlaufen. Einige dieser Schritte sind mithilfe von Shadern beeinflussbar, andere wiederum nicht. Die Render Pipeline erhält zu Beginn einzelne Punkte (Vertices) als Input. Die Position dieser Punkte kann mithilfe eines Vertex Shaders vom Programmierer beeinflusst werden. Anschliessend werden diese Punkte zu Dreiecken zusammengesetzt (Primitive Assembly). Damit die Dreiecke jedoch auf einem Bildschirm dargestellt werden können, müssen diese zuerst rasterisiert, d.h. in darstellbare Pixel umgewandelt werden (Rasterization). Der Programmierer hat nun wiederum die Möglichkeit die Farbe dieser Pixel innerhalb des Fragment Shaders zu beeinflussen. Als letzten Schritt werden die darstellbaren Pixel in einen Frame Buffer geladen und auf dem Bildschirm dargestellt. An dieser Stelle sei angemerkt dass es noch andere Zwischenschritte in der Render Pipeline wie Geometry Shader gibt, diese jedoch in dieser Arbeit nicht weiter besprochen werden.

\section{Shader}
Shader sind kleine Computerprogramme, welche direkt auf der Grafikkarte ausgeführt werden. Anders als der Prozessor (CPU) welcher Arbeiten sequenziell verrichtet, laufen Programme auf der Grafikkarten parallel ab. Dieses Konzept ist wichtig zu verstehen, da der Shadercode sequenziell aussehen mag, aber in Wirklichkeit parallel abläuft. Die Shader werden in einer dedizierten Programmiersprache (abhängig je nach Grafikschnittstelle) geschrieben. Shader sind vom Prinzip her sehr einfach gestrickt, sie nehmen einen Dateninput und produzieren einen Datenoutput bzw. geben diesen an den nächsten Shader weiter. Nachfolgend wird auf die wichtigsten Terminologien und Konzepte in Bezug auf Shader eingegangen.

\subsection{Vertex Shader}
Mithilfe des Vertex Shaders kann die Position der einzelnen Vertices verändert werden. Ein Vertex Shader kann beispielsweise benutzt werden, um die einzelnen Punkte abhängig von den gemessenen Höhenwerten des swissALTI3D-Datensatzes (siehe Kapitel \ref{chap_datengrundlage}) zu platzieren, und erlaubt es so, die Geometrie des Gebirges in 3D zu rekonstruieren.

\subsection{Fragment Shader}
Der Fragment Shader beeinflusst die Farbe eines einzelnen Pixels. Hierbei muss der Farbwert aber nicht wie in Abbildung \ref{fig_fragment_shader} dargestellt fix festgelegt  werden, sondern kann auch von einer Textur (Bilddatei) gelesen werden. In Kombination mit dem swissIMAGE-Datensatz kann somit das Aussehen des Gebirges rekonstruiert werden.
\begin{figure}[H]
    \caption{Beispiel Fragment Shader \parencite{book_of_shaders_fragment_shader_2025}}
    \includegraphics[width=.5\linewidth]{content/00_assets/beispiel_shader.png}
    \label{fig_fragment_shader}
\end{figure}

\subsection{Compute Shader}
\label{chap_compute_shader}
Anders als der Vertex sowie der Fragment Shader welche sich innerhalb einer fixen Pipeline befinden und nur jeweils einen zentralen Aspekt (Position und Farbe) beeinflussen können, kann der Compute Shader für generelle Rechenaufgaben verwendet werden. Somit können rechenintensive Aufgaben, welche sonst normalerweise auf dem Prozessor laufen, auf die Grafikkarte ausgelagert und somit um Faktoren beschleunigt werden. Hiermit ist beispielsweise eine hydraulische Errosionssimulation für ein Gebirge, d.h. wie Wasser die Beschaffenheit des Gebirges über die Zeit verändert, in Echtzeit möglich.


\subsection{Attributes und Uniforms}
Shaderprogramme werden, wie bereits erwähnt, parallel ausgeführt. Hierbei spielen Attributes und Uniforms eine wichtige Rolle. Uniforms sind Werte, welche für jede Instanz welche ausgeführt wird, gleich sind, d.h. jede Instanz sieht den gleichen Wert. Kandidaten für Uniforms sind unter anderem die aktuelle Kameraposition sowie die Zeit. Attributes hingegen sind Werte welche sich für jeden Punkt (Vertex) unterscheiden. Hierzu zählen etwa die aktuelle Position des Punktes oder der zugehörige Normalvektor.

\section{Texturen}
3D-Modelle bestehen neben der eigentlichen Geometrie, welche die Struktur vorgibt, auch aus Texturen. Texturen sind Bilddateien, welche auf die eigentliche Geometrie projiziert werden (siehe Abbildung \ref{fig_texturen}). 
\begin{figure}[H]
    \caption{Projizierung von Texturen auf Geometrie \parencite{learnopengl_pbr_2016}}
    \includegraphics[width=.4\linewidth]{content/00_assets/texturen.png}
    \label{fig_texturen}
\end{figure}
Eine Textur muss hierbei jedoch nicht nur Farbwerte sondern kann auch Informationen über Höhenwerte (Heightmap) oder Normalvektoren (Normalmap) beinhalten. Diese Informationen können anschliessend mithilfe von Shadern kombiniert werden, um eine sehr detailgetreue 3D Visualisierung zu gestalten (siehe Abbildung \ref{fig_texturen_kombiniert}).
\begin{figure}[H]
    \caption{Kombination von verschiedenen Texturen für eine detailreiche Darstellung \parencite{learnopengl_pbr_2016}}
    \includegraphics[width=.4\linewidth]{content/00_assets/texturen_kombiniert.png}
    \label{fig_texturen_kombiniert}
\end{figure}